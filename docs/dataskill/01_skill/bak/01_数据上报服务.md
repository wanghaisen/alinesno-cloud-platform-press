# 数据上报服务

## 概述 

提供统一的数据上报入口。业务员下载导入模板，填写数据后进行上报。系统接收数据信息并写入数据仓库。

## 本内容你将获得

- 如何上报数据

## 上报步骤

- 系统侧编制、上传导入模板
- 系统侧配置入库信息
- 系统侧开发部署数据入湖代码
- 业务员下载导入模板
- 业务员填报数据
- 业务员上报数据

### 系统侧编制、上传导入模板

#### 1、编制导入模板

 新建*.xlsx文件，根据需求填写字段名称、字段英文名称、字段含义、是否必填、数据类型、枚举值、数据样例。参考下图

<img :src="$withBase('/operation/data_hudi_01.png')">

第1行到第7行为导入模板信息。用户下载导入模板后，从第8行开始填写上报信息，其中第1列为数据序号。填写完后，为数据加上框线。

#### 2、上传导入模板

进入数据上报服务，导航到上传-上传文件，选择导入模板文件，上传

### 系统侧配置入库信息

进入数据上报服务，导航到我的文件-全部，找到上一步上传的导入模板文件，设置入库配置信息。

入库配置信息如下

<img :src="$withBase('/operation/data_hudi_05.png')">

配置说明：

- 数据模型选择是

- 项目名称、库名、表名描述数据来源

- 开发人员根据kafka主题、kafka表、hudi表、入库信息编写入库代码
- 维护人员根据kafka主题、kafka表、hudi表、入库信息进行维护

### 系统侧开发部署数据入湖代码

#### 1、开发代码

 在alinesno-data-hudi工程中，新建入库类。参考ElectricityBill类

```java
package com.alinesno.cloud.data.hudi.kafka;

import org.apache.flink.api.common.restartstrategy.RestartStrategies;
import org.apache.flink.runtime.state.filesystem.FsStateBackend;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.environment.CheckpointConfig;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.table.api.EnvironmentSettings;
import org.apache.flink.table.api.Table;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import static org.apache.flink.table.api.Expressions.$;


public class ElectricityBill {

    public   void slinkElectricityBill() {

        //1.获取表的执行环境
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        //2.1设置检查点信息
        //由于增量将数据写入到hudi表，所以需要启动Flink Checkpoint检查点
        env.setParallelism(2);           //并行度

        //每 5 * 1000 ms 开始执行检查点
        env.enableCheckpointing(5 * 1000);

        CheckpointConfig checkpointconf = env.getCheckpointConfig();

        // make sure 3000 ms of progress happen between checkpoints
        checkpointconf.setMinPauseBetweenCheckpoints(3000l);

        // checkpoints have to complete within one minute, or are discarded
        checkpointconf.setCheckpointTimeout(60000l);

        //2.2 指定 CK 的一致性语义
        env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
        //2.3 设置任务关闭的时候保留最后一次 CK 数据
        env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION);
        //2.4 指定从 CK 自动重启策略
        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(30, 2000L));
        //2.5 设置检查点的存储文件
        env.setStateBackend(new FsStateBackend("hdfs://172.17.49.195:9000/user/flink/hudi/ck/sink_electricity_bill"));


        EnvironmentSettings settings = EnvironmentSettings
                .newInstance()
                .inStreamingMode()//设置流式模式
                .build();
        //2.6 设置访问 HDFS 的用户名
        System.setProperty("HADOOP_USER_NAME", "root");
        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);


        //3.创建输入表，TODO:从kafka消费数据
        tableEnv.executeSql(
                "create table electricity_bill_kafka_source(\n" +
                        "    billing_month STRING,\n" +
                        "    provinces     STRING,\n" +
                        "    local_market  STRING,\n" +
                        "    county        STRING,\n" +
                        "    meter_number  STRING,\n" +
                        "    pay_amount    double \n" +
                        ")\n" +
                        "WITH(\n" +
                        "    'connector' = 'kafka',\n" +
                        "    'topic'='electricity_bill',\n" +
                        "    'properties.bootstrap.servers' = '172.17.49.195:9092',\n" +
                        "    'properties.group.id' = 'testgroup1',\n" +
                        "    'scan.startup.mode' = 'earliest-offset',\n" +
                        "    'format' = 'json'                      ,\n" +
                        "    'json.fail-on-missing-field' = 'false' ,\n" +
                        "    'json.ignore-parse-errors' = 'true'     \n" +
                        ")\n"
        );

 

        //4.创建输出表，TODO:关联到hudi表，指定hudi表名称，存储路径，字段名称等信息
        tableEnv.executeSql(
                "create table electricity_bill_hudi_sink(\n" +
                        "    billing_month STRING ,\n" +
                        "    provinces     STRING ,\n" +
                        "    local_market  STRING ,\n" +
                        "    county        STRING ,\n" +
                        "    meter_number  STRING PRIMARY KEY NOT ENFORCED ,\n" +
                        "    pay_amount    double ,\n" +
                        "    `part` VARCHAR(20) \n" +
                        ")\n" +
                        "PARTITIONED BY (`part`)\n" +
                        "WITH(\n" +
                        "    'connector' = 'hudi',\n" +
                        "    'path'='hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi',\n" +
                        "    'table.type' = 'COPY_ON_WRITE',\n" +
                        "    'write.operation' = 'upsert',\n" +
                        "    'write.tasks' = '1', \n" +
                        "    'hive_sync.enable'='true', -- required，开启hive同步功能\n" +
                        "    'hive_sync.mode' = 'hms', -- required, 将hive sync mode设置为hms, 默认jdbc\n" +
                        "    'hive_sync.metastore.uris' = 'thrift://172.17.49.195:9083', -- metastore的端口\n" +
                        "    'hive_sync.db' = 'test', -- hive新建数据库名\n" +
                        "    'hive_sync.table' = 'flink_electricity_bill_hudi', -- hive新建表名\n" +
                        "    'hive_sync.support_timestamp' = 'true' -- 兼容hive timestamp类型\n" +
                        ")\n"
        );

        //5.通过子查询的方式，将数据写入输出表
        tableEnv.executeSql(
                "insert into electricity_bill_hudi_sink " +
                        " select billing_month, provinces, local_market, county, meter_number, pay_amount, billing_month from electricity_bill_kafka_source "
        );


    }
}


```

代码说明：

- 设置检查点的存储文件
- 创建输入表、输出表。按照业务需求加工输入表数据后写入输出表

在主类中，调用类。如ElectricityBill

```java
package com.alinesno.cloud.data.hudi.kafka;

public class kafkaMain {

    public static void main(String[] args) {

        //kafka接收数据上报服务数据，入库到hudi表
        ElectricityBill electricityBill = new ElectricityBill();
        electricityBill.slinkElectricityBill();

    }
}
```

#### 2、编译代码

编译alinesno-data-hudi工程

<img :src="$withBase('/operation/data_hudi_10.png')">

#### 3、部署jar包

将jar包上传到flink的Submit New Job界面，设置运行主类后提交。在Jobs-Running Jobs界面，检查到任务正常运行，即可等待数据上报。

a)、查看部署信息

<img :src="$withBase('/operation/data_hudi_17.png')">

b)、查看部署结果

查看hudi表对应的hdfs数据

```shell
[root@hadoopmaster ~]# hadoop fs -ls hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi
Found 2 items
drwxr-xr-x   - root supergroup          0 2022-09-20 09:52 hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/.hoodie
drwxr-xr-x   - root supergroup          0 2022-09-20 09:52 hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/202201
[root@hadoopmaster ~]# hadoop fs -ls hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/202201
Found 3 items
-rw-r--r--   3 root supergroup         96 2022-09-20 09:52 hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/202201/.hoodie_partition_metadata
-rw-r--r--   3 root supergroup     436476 2022-09-20 09:52 hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/202201/2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet
-rw-r--r--   3 root supergroup     436415 2022-09-20 09:52 hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/202201/949f774e-cce5-4c53-8436-0f39582f3041_0-1-0_20220920095216264.parquet
[root@hadoopmaster ~]# 
```

查看映射的hive表数据

```shell
hive> use test;
OK
Time taken: 0.029 seconds
hive> show tables;
OK
flink_electricity_bill_hudi
Time taken: 0.032 seconds, Fetched: 1 row(s)
hive> select *from flink_electricity_bill_hudi ;
OK
20220920095216264       20220920095216264_0_0   500300521431    202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  500300521431    599.35  202201
20220920095216264       20220920095216264_0_1   5639183901      202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  5639183901      760.34  202201
20220920095216264       20220920095216264_0_2   0201003677651   202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  0201003677651   590.87  202201
20220920095216264       20220920095216264_0_3   500048937031    202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  500048937031    28681.0 202201
20220920095216264       20220920095216264_0_4   5639078671      202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  5639078671      422.62  202201
20220920095216264       20220920095216264_0_5   5901128771      202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  5901128771      164.14  202201
20220920095216264       20220920095216264_0_6   500048182501    202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  500048182501    598.71  202201
20220920095216264       20220920095216264_0_7   219530951       202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  219530951       495.16  202201
20220920095216264       20220920095216264_0_8   500421725501    202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  500421725501    412.56  202201
20220920095216264       20220920095216264_0_9   5639212151      202201  2304c08d-af1f-4356-8fb3-bbf739c30aad_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  5639212151      707.51  202201
20220920095216264       20220920095216264_0_0   500067512491    202201  949f774e-cce5-4c53-8436-0f39582f3041_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  500067512491    1166.61 202201
20220920095216264       20220920095216264_0_1   04121SF000000019005694161       202201  949f774e-cce5-4c53-8436-0f39582f3041_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  04121SF000000019005694161       1021.96 202201
20220920095216264       20220920095216264_0_2   500226762451    202201  949f774e-cce5-4c53-8436-0f39582f3041_0-1-0_20220920095216264.parquet    202201  广西    南宁    良庆区  500226762451    1250.37 202201
Time taken: 1.245 seconds, Fetched: 13 row(s)
hive> 
```

配置说明

- 删除测试数据  hdfs dfs -rm -r  hdfs://172.17.49.195:9000/user/flink/hudi/flink_electricity_bill_hudi/202201 

### 业务员下载导入模板

进入数据上报服务，导航到我的文件-全部，通过上传-上传报表表格进入报表表格导入界面，选择报表模板，下载数据模板。

<img :src="$withBase('/operation/data_hudi_18.png')">

### 业务员填报数据

按照导入模板填写好数据。

进入数据上报服务，导航到我的文件-全部，通过上传-上传报表表格进入报表表格导入界面，上传数据文件。

### 业务员上报数据

进入数据上报服务，导航到我的文件-全部，通过上传-上传报表表格进入报表表格导入界面，从云存储提取数据文件到服务器，上报数据。

备注:

上报数据时，系统将校验数据文件。校验通过后，将数据发送到消息总线。服务端接收到消息后，实时写入数仓。



 





